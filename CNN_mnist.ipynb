{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 卷积神经网络(CNN)  mnist数据集\n",
    "`凌鑫杰`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "_导入模块_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "# % matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##定义超参数\n",
    "input_size = 28  #图形总尺寸28*28\n",
    "num_classes = 10  #标签的种类数\n",
    "num_epochs = 3  #训练总循环周期\n",
    "batch_size = 64  #一个撮(批次)的大小，64张图片\n",
    "##训练集\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "##测试集\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor())\n",
    "\n",
    "##构建batch数据\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 定义卷积神经网络模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_1 = nn.Sequential(  #输入大小\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,  #灰度图\n",
    "                out_channels=16,  #卷积核个数(特征图个数)\n",
    "                kernel_size=5,  #卷积核大小(选择区域大小)\n",
    "                stride=1,  #滑动窗口步长\n",
    "                padding=2,  #边缘填充\n",
    "            ),  #输出特征图为(16,28,28)\n",
    "            nn.ReLU(),  #RELU层(激活层)\n",
    "            nn.MaxPool2d(kernel_size=2),  #进行池化操作，输出结果：(16,14,14)\n",
    "        )\n",
    "        self.conv_2 = nn.Sequential(  #第一层卷积的输入(16,14,14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),  #输出(32,14,14)\n",
    "            nn.ReLU(),  #RULU层(激活层)\n",
    "            nn.MaxPool2d(2),  #输出(32,7,7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)  #全连接层得到的结果\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    pred = torch.max(predictions.data, 1)[1]\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum()\n",
    "    return rights, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前epoch：0[0/60000(0%)]\t损失：2.299800\t训练集准确率：12.50%\t测试集正确率：10.56%\n",
      "当前epoch：0[6400/60000(11%)]\t损失：0.270555\t训练集准确率：76.05%\t测试集正确率：90.80%\n",
      "当前epoch：0[12800/60000(21%)]\t损失：0.144860\t训练集准确率：84.65%\t测试集正确率：94.68%\n",
      "当前epoch：0[19200/60000(32%)]\t损失：0.110791\t训练集准确率：87.99%\t测试集正确率：95.93%\n",
      "当前epoch：0[25600/60000(43%)]\t损失：0.097812\t训练集准确率：89.94%\t测试集正确率：96.73%\n",
      "当前epoch：0[32000/60000(53%)]\t损失：0.101021\t训练集准确率：91.21%\t测试集正确率：97.33%\n",
      "当前epoch：0[38400/60000(64%)]\t损失：0.091958\t训练集准确率：92.15%\t测试集正确率：97.50%\n",
      "当前epoch：0[44800/60000(75%)]\t损失：0.025826\t训练集准确率：92.92%\t测试集正确率：97.73%\n",
      "当前epoch：0[51200/60000(85%)]\t损失：0.016574\t训练集准确率：93.53%\t测试集正确率：97.90%\n",
      "当前epoch：0[57600/60000(96%)]\t损失：0.074326\t训练集准确率：93.98%\t测试集正确率：98.09%\n",
      "当前epoch：1[0/60000(0%)]\t损失：0.171017\t训练集准确率：95.31%\t测试集正确率：98.19%\n",
      "当前epoch：1[6400/60000(11%)]\t损失：0.041638\t训练集准确率：98.17%\t测试集正确率：98.18%\n",
      "当前epoch：1[12800/60000(21%)]\t损失：0.045806\t训练集准确率：98.09%\t测试集正确率：98.10%\n",
      "当前epoch：1[19200/60000(32%)]\t损失：0.090600\t训练集准确率：98.08%\t测试集正确率：98.56%\n",
      "当前epoch：1[25600/60000(43%)]\t损失：0.122465\t训练集准确率：98.16%\t测试集正确率：98.30%\n",
      "当前epoch：1[32000/60000(53%)]\t损失：0.010164\t训练集准确率：98.20%\t测试集正确率：98.40%\n",
      "当前epoch：1[38400/60000(64%)]\t损失：0.015833\t训练集准确率：98.21%\t测试集正确率：98.72%\n",
      "当前epoch：1[44800/60000(75%)]\t损失：0.172506\t训练集准确率：98.22%\t测试集正确率：98.62%\n",
      "当前epoch：1[51200/60000(85%)]\t损失：0.035283\t训练集准确率：98.24%\t测试集正确率：98.61%\n",
      "当前epoch：1[57600/60000(96%)]\t损失：0.040319\t训练集准确率：98.24%\t测试集正确率：98.64%\n",
      "当前epoch：2[0/60000(0%)]\t损失：0.091749\t训练集准确率：98.44%\t测试集正确率：98.62%\n",
      "当前epoch：2[6400/60000(11%)]\t损失：0.028715\t训练集准确率：98.51%\t测试集正确率：98.65%\n",
      "当前epoch：2[12800/60000(21%)]\t损失：0.003938\t训练集准确率：98.64%\t测试集正确率：98.77%\n",
      "当前epoch：2[19200/60000(32%)]\t损失：0.063750\t训练集准确率：98.66%\t测试集正确率：98.87%\n",
      "当前epoch：2[25600/60000(43%)]\t损失：0.079262\t训练集准确率：98.69%\t测试集正确率：98.74%\n",
      "当前epoch：2[32000/60000(53%)]\t损失：0.029023\t训练集准确率：98.72%\t测试集正确率：98.88%\n",
      "当前epoch：2[38400/60000(64%)]\t损失：0.081883\t训练集准确率：98.71%\t测试集正确率：98.83%\n",
      "当前epoch：2[44800/60000(75%)]\t损失：0.073151\t训练集准确率：98.69%\t测试集正确率：98.95%\n",
      "当前epoch：2[51200/60000(85%)]\t损失：0.057825\t训练集准确率：98.72%\t测试集正确率：98.84%\n",
      "当前epoch：2[57600/60000(96%)]\t损失：0.006502\t训练集准确率：98.73%\t测试集正确率：98.90%\n"
     ]
    }
   ],
   "source": [
    "#实例化\n",
    "net = CNN()\n",
    "#损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#优化器\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  #定义优化器，普通的随机梯度下降算法\n",
    "\n",
    "#开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    #当前epoch结果保存下来\n",
    "    train_rights = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  #针对容器中每一个批进行循环\n",
    "        net.train()\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        right = accuracy(output, target)\n",
    "        train_rights.append(right)\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            net.eval()\n",
    "            val_rights = []\n",
    "\n",
    "            for (data, target) in test_loader:\n",
    "                output = net(data)\n",
    "                right = accuracy(output, target)\n",
    "                val_rights.append(right)\n",
    "\n",
    "            #准确率计算\n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "\n",
    "            print(\"当前epoch：{}[{}/{}({:.0f}%)]\\t损失：{:.6f}\\t训练集准确率：{:.2f}%\\t测试集正确率：{:.2f}%\".format(\n",
    "                epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader),\n",
    "                loss.data,\n",
    "                       100. * train_r[0].numpy() / train_r[1],\n",
    "                       100. * val_r[0].numpy() / val_r[1]\n",
    "            ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset MNIST\n    Number of datapoints: 60000\n    Root location: ./data\n    Split: Train\n    StandardTransform\nTransform: ToTensor()"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch",
   "language": "python",
   "display_name": "PyTorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}